{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decompose MOB data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply NMF or sICA factorization to MOB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "curdir = os.path.abspath(os.path.curdir)\n",
    "sys.path.append(os.path.join(curdir,'FUImaging'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configobj import ConfigObj\n",
    "import glob\n",
    "import numpy as np\n",
    "from regnmf import ImageAnalysisComponents as ia\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basepath = os.path.join('/media/jan/BackupWork/Documents/NewAnalysis')\n",
    "toplevelpath = os.path.realpath(os.path.pardir)\n",
    "datapath = os.path.join(toplevelpath, 'Soelter_et_al_raw_data')\n",
    "savepath = os.path.join(toplevelpath, 'MOBdecomposed') #where to save decompostion\n",
    "savepath_vis = '/home/jan/Dokumente/MOBData/Vis/Factorizations' #where to save visualization of decomposition\n",
    "cfgfile = os.path.join(toplevelpath, 'configfiles', 'decompose', 'nnmf_50_sm2_convex_negTimelowSP.ini') #'sica_200.ini') #\n",
    "datafile = 'sph_meas'#'ios_meas'\n",
    "response_window = (8,12) #define frames to calculate odor response; ios:(3,5) sph:(8,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = '120217FRVg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs NMF factorization according to config file. The sparsness parameter is choosen iterativly: First start with 'sparse_start' as initial guess. Sparseness will increase in steps of 'sparse_increase' until spatial component correlation of stimulus dependent components drops below 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/sam/Documents/Repos/Soelter_et_al_raw_data/120217FRVg/sph_meas.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-8d52edd5d491>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mfilename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdatapath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0manimal\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdatafile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0mts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mia\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTimeSeries\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m \u001B[0mts\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0mcfg\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'sparse_param'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msparse_start\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Repos/glomcentric_code/FUImaging/regnmf/ImageAnalysisComponents.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(self, filename)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    128\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 129\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__dict__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'.json'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    130\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfile\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mabspath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    131\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_series\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'.npy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/sam/Documents/Repos/Soelter_et_al_raw_data/120217FRVg/sph_meas.json'"
     ]
    }
   ],
   "source": [
    "sparse_start = 0.2 #inital sparseness strength\n",
    "assert 'nnmf' in cfgfile\n",
    "\n",
    "    \n",
    "#load config\n",
    "cfg = ConfigObj(cfgfile, unrepr=True)\n",
    "\n",
    "\n",
    "\n",
    "#load data\n",
    "filename = os.path.join(datapath, animal, datafile)\n",
    "ts = ia.TimeSeries()\n",
    "ts.load(filename)\n",
    "\n",
    "cfg['sparse_param'] = sparse_start\n",
    "cfg['verbose'] = 1\n",
    "cfg['smooth_param'] = 5\n",
    "cfg['num_components'] = 20\n",
    "\n",
    "# perform decomposition\n",
    "decomposer = ia.NNMF(**cfg)\n",
    "decomposition = decomposer(ts)\n",
    "decomposition.base._series[np.isnan(decomposition.base._series)] = 0 #clear nans\n",
    "    \n",
    "# calc spatial cor of stimulus driven components\n",
    "signal = ia.TrialMean()(ia.CutOut(response_window)(decomposition))\n",
    "mode_cor = ia.CalcStimulusDrive()(signal)\n",
    "mask = mode_cor._series.squeeze()<0.5\n",
    "if np.sum(mask) != 0: #if there are stimulus driven components  \n",
    "    selected_modes = ia.SelectObjects()(decomposition, mask)   \n",
    "    cor = np.nanmax(1-pdist(selected_modes.base._series, 'correlation'))\n",
    "else:\n",
    "    cor = np.nanmax(1-pdist(decomposition.base._series, 'correlation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "ConfigObj({})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "for ix, base in enumerate(decomposition.base.shaped2D()):\n",
    "    mycolors = ['c', 'b'] if mode_cor._series.squeeze()[ix] <0.4 else ['0.3', '0.7']\n",
    "    if decomposition.name.split('_')[1] == 'l':\n",
    "        base  = base[::-1]    \n",
    "    ax.contourf(base, [0.3,0.7,1], colors=mycolors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nanmax(1-pdist(decomposition.base._series, 'correlation')))\n",
    "\n",
    "\n",
    "for ix, base in enumerate(decomposition.base.shaped2D()):\n",
    "    ax = plt.subplot(8,7,ix+1)\n",
    "    ax.imshow(base, vmin=0, vmax=1, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sICA factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redo = True\n",
    "assert 'sica' in cfgfile\n",
    "animals = [ani for ani in os.listdir(datapath) if ('FRV' in ani)] #('FRV' not in ani)]\n",
    "\n",
    "for animal in animals:\n",
    "    \n",
    "    savelocation = os.path.join(savepath, animal)\n",
    "    savename = os.path.splitext(os.path.basename(cfgfile))[0] + '_' + datafile\n",
    "    if os.path.exists(savelocation):\n",
    "        if os.path.exists(os.path.join(savelocation, savename + '.npy')) and not(redo):\n",
    "            print('%s already done'%animal)\n",
    "            continue\n",
    "    else:\n",
    "        os.makedirs(savelocation)\n",
    "        \n",
    "    filename = os.path.join(datapath, animal, datafile)\n",
    "    ts = ia.TimeSeries()\n",
    "    try:\n",
    "        ts.load(filename)\n",
    "    except IOError:\n",
    "        print('!!! No data for animal %s !!!'%animal)\n",
    "        continue\n",
    "    cfg = ConfigObj(cfgfile, unrepr=True)\n",
    "        \n",
    "    # perform decomposition\n",
    "    decomposer = ia.sICA(**cfg)\n",
    "    decomposition = decomposer(ts)\n",
    "    decomposition.base._series[np.isnan(decomposition.base._series)] = 0 #clear nans\n",
    "   \n",
    "    decomposition.save(os.path.join(savelocation, savename))\n",
    "    print('%s done'%animal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot decomposition overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot decompositions for selected animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'sica_200_ios_meas'#'nnmf_200_sm2_convex_negTimelowSP_sp*_ios_meas'\n",
    "draw_sphrois = True\n",
    "animals = [ani for ani in os.listdir(savepath) if ('FRV' not in ani)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.ceil(len(animals)/5.)\n",
    "fig = plt.figure(figsize=(10, 1.5*int(rows)))\n",
    "plt.subplots_adjust(left=0.02, bottom=0.02, right=0.98, top=0.9)\n",
    "\n",
    "for ix, animal in enumerate(animals):\n",
    "    ax = fig.add_subplot(rows, 5, ix+1)\n",
    "    bg = Image.open(os.path.join(datapath, animal, 'bg.png'))\n",
    "    bg = bg.convert('L')\n",
    "    \n",
    "    mf = ia.TimeSeries()\n",
    "    filename = glob.glob(os.path.join(savepath, animal, method+'.npy'))\n",
    "    assert len(filename) == 1\n",
    "    filename = filename[0].split('.')[0]\n",
    "    mf.load(filename)\n",
    "    \n",
    "    bg = bg.resize(mf.base.shape[::-1])\n",
    "    bg = np.asarray(bg)\n",
    "    if mf.name.split('_')[1] == 'l':\n",
    "        bg = bg[::-1]    \n",
    "       \n",
    "    mf = ia.TrialMean()(ia.CutOut(response_window)(mf))\n",
    "    t2t = ia.CalcStimulusDrive()(mf)._series.squeeze()\n",
    "    \n",
    "    myextent = np.array([0, mf.base.shape[1], mf.base.shape[0], 0])-0.5\n",
    "    ax.imshow(bg, interpolation='none', extent=myextent, cmap=plt.cm.bone)\n",
    "    for ix, base in enumerate(mf.base.shaped2D()):\n",
    "        mycolors = ['c', 'b'] if t2t[ix] <0.4 else ['0.3', '0.7']\n",
    "        if mf.name.split('_')[1] == 'l':\n",
    "            base  = base[::-1]    \n",
    "        ax.contourf(base, [0.3,0.7,1], colors=mycolors, alpha=0.5)\n",
    "    \n",
    "    #show rois\n",
    "    roi_path = os.path.join(datapath, animal, 'rois')\n",
    "    if draw_sphrois and os.path.exists(roi_path+'.npy'):\n",
    "        rois = ia.TimeSeries()\n",
    "        rois.load(roi_path)\n",
    "        for roi in rois.shaped2D():\n",
    "            if mf.name.split('_')[1] == 'l':\n",
    "                roi = roi[::-1]\n",
    "            ax.contour(roi, [0.5], colors=['w'], lw=2)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(animal, size=8)\n",
    "    \n",
    "fig.savefig(os.path.join(savepath_vis, method+'.pdf'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}